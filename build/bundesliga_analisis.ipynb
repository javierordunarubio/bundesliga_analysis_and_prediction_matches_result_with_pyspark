{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bundesliga analysis and match result prediction \n",
    "- [Bundesliga analysis and match result prediction](#toc1_)    \n",
    "  - [Loading of the dfs and extraction of some information](#toc1_1_)    \n",
    "  - [Questions answers](#toc1_2_)    \n",
    "  - [Random Forest model to predict result](#toc1_3_)    \n",
    "    - [Prediction of matches with wins, losses and draws](#toc1_3_1_)    \n",
    "    - [Prediction of matches with no Draws](#toc1_3_2_)    \n",
    "  - [Conclussions](#toc1_4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "In this notebook we are going to make an **analysis of some data of the first football division in Germany using Pyspark**, extracting some information of each season: champions of the league year by year, relegated ones of each season and season with more goals. We'll also see the teams with more economic power and the stadiums with more capacity. Finally, we will do a **simple model also with Pyspark using a Random Forest** with which we'll try to predict the results of the football matches with some independent variables (this will be very difficult, as we'll see later).\n",
    "\n",
    "**It's necessary to clear that the main goals of this work is to extract some conclussions of the data we have through some data transformations and build a simple ML pipeline, doing both things using the library Pyspark.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Loading of the dfs and extraction of some information](#toc0_)\n",
    "\n",
    "As data we have four dataframes, which have already suffered some transformations (ETL process): they are already propperly formatted, without NaNs, stored in csv format:\n",
    "* A dataframe called Matches.csv with the result of the matches of some different seasons.\n",
    "* A dataframe called Teams.csv with the information of the different teams.\n",
    "* A dataframe called Unique_Teams.csv with the IDS of the teams. In this df we have teams from Germany and England for the first and the second division.\n",
    "\n",
    "\n",
    "The first step is to load the necessary libraries and start the spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 16:04:20 WARN Utils: Your hostname, javier-VivoBook resolves to a loopback address: 127.0.1.1; using 192.168.1.136 instead (on interface wlo1)\n",
      "23/03/30 16:04:20 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 16:04:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName(\"bundesliga_analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load of Unique_Teams df**\n",
    "\n",
    "We are going to start with the load of this df because we want to ensure that we don't get any team from outside of Germany. Let's load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|     TeamName|Unique_Team_ID|\n",
      "+-------------+--------------+\n",
      "|Bayern Munich|             1|\n",
      "|     Dortmund|             2|\n",
      "+-------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('TeamName', 'string'), ('Unique_Team_ID', 'int')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_teams = spark.read.option(\"header\",True).option(\"inferSchema\" , \"true\").csv(\"./data/Unique_Teams.csv\")\n",
    "unique_teams.show(2)\n",
    "unique_teams.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have two columns, which are of the correct data type. Looking directly at the raw csv, we have realised that the german teams with have an Unique_Team_ID value <= 80, while the English Teams have a greater ID. Knowing this what we are going to do is to filter the df using this ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+\n",
      "|    TeamName|Unique_Team_ID|\n",
      "+------------+--------------+\n",
      "|Wattenscheid|            76|\n",
      "| Wuppertaler|            77|\n",
      "|     Zwickau|            78|\n",
      "|    RW Essen|            79|\n",
      "|  M'Gladbach|            80|\n",
      "|     Arsenal|            81|\n",
      "| Aston Villa|            82|\n",
      "|     Chelsea|            83|\n",
      "|   Liverpool|            84|\n",
      "|    Man City|            85|\n",
      "+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_teams.filter(\n",
    "    F.col('Unique_Team_ID') > 75\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could have been done doing a web scrapping of teams of both leagues in such a way that every team had a Country variable (or directly downloading the csvs from Internet, they're available there), joining this dfs and filtering in order to get the german ones. Nevertheless, the objective of this project is to use pyspark, so we'll do in the faster way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|     TeamName|Unique_Team_ID|\n",
      "+-------------+--------------+\n",
      "|Bayern Munich|             1|\n",
      "|     Dortmund|             2|\n",
      "+-------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_german_teams = unique_teams.filter(\n",
    "    F.col('Unique_Team_ID') <= 80\n",
    ")\n",
    "unique_german_teams.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load of the teams df**\n",
    "\n",
    "Now we are going to load and take a look at the teams df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+----------+------------------+---------------+\n",
      "|Season|     TeamName|AvgAgeHome|OverallMarketValue|StadiumCapacity|\n",
      "+------+-------------+----------+------------------+---------------+\n",
      "|  2017|Bayern Munich|        26|         597950000|          75000|\n",
      "|  2017|     Dortmund|        25|         416730000|          81359|\n",
      "|  2017|   Leverkusen|        24|         222600000|          30210|\n",
      "|  2017|   RB Leipzig|        23|         180130000|          42959|\n",
      "|  2017|   Schalke 04|        24|         179550000|          62271|\n",
      "+------+-------------+----------+------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teams = spark.read.option(\"header\",True).option(\"inferSchema\" , \"true\").csv(\"./data/Teams.csv\")\n",
    "teams.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the number of differents teams in our csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams.select('TeamName').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 57 different teams. Let's do an inner join with the df unique_german_teams df by the TeamName in order to ensure we just have german teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+----------+------------------+---------------+\n",
      "|     TeamName|Season|AvgAgeHome|OverallMarketValue|StadiumCapacity|\n",
      "+-------------+------+----------+------------------+---------------+\n",
      "|Bayern Munich|  2017|        26|         597950000|          75000|\n",
      "|     Dortmund|  2017|        25|         416730000|          81359|\n",
      "|   Leverkusen|  2017|        24|         222600000|          30210|\n",
      "|   RB Leipzig|  2017|        23|         180130000|          42959|\n",
      "|   Schalke 04|  2017|        24|         179550000|          62271|\n",
      "|   M'gladbach|  2017|        25|         154400000|          54014|\n",
      "|    Wolfsburg|  2017|        24|         124430000|          30000|\n",
      "|      FC Koln|  2017|        26|         118550000|          49968|\n",
      "|   Hoffenheim|  2017|        24|         107330000|          30164|\n",
      "|       Hertha|  2017|        26|          86800000|          74475|\n",
      "|        Mainz|  2017|        25|          71950000|          34000|\n",
      "|      Hamburg|  2017|        25|          71550000|          57376|\n",
      "|Werder Bremen|  2017|        26|          69450000|          42100|\n",
      "|Ein Frankfurt|  2017|        24|          67100000|          51500|\n",
      "|     Augsburg|  2017|        26|          63100000|          30660|\n",
      "|     Freiburg|  2017|        26|          57730000|          24000|\n",
      "|    Stuttgart|  2017|        24|          44750000|          60449|\n",
      "|     Hannover|  2017|        25|          43100000|          49200|\n",
      "|Bayern Munich|  2016|        25|         595400000|          75000|\n",
      "|     Dortmund|  2016|        24|         321550000|          81359|\n",
      "+-------------+------+----------+------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teams = teams.join(\n",
    "    unique_german_teams,on='TeamName',how='inner'\n",
    ").drop('Unique_Team_ID')\n",
    "teams.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's show the two teams with more market value for each season:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+------------------+\n",
      "|Season|     TeamName|OverallMarketValue|\n",
      "+------+-------------+------------------+\n",
      "|  2005|Bayern Munich|         171500000|\n",
      "|  2005|Werder Bremen|          93800000|\n",
      "|  2006|Bayern Munich|         166980000|\n",
      "|  2006|Werder Bremen|         128680000|\n",
      "|  2007|Bayern Munich|         222930000|\n",
      "|  2007|Werder Bremen|         129030000|\n",
      "|  2008|Bayern Munich|         238900000|\n",
      "|  2008|Werder Bremen|         142450000|\n",
      "|  2009|Bayern Munich|         283250000|\n",
      "|  2009|    Wolfsburg|         155880000|\n",
      "|  2010|Bayern Munich|         284500000|\n",
      "|  2010|    Wolfsburg|         210730000|\n",
      "|  2011|Bayern Munich|         335600000|\n",
      "|  2011|     Dortmund|         158200000|\n",
      "|  2012|Bayern Munich|         407300000|\n",
      "|  2012|     Dortmund|         227680000|\n",
      "|  2013|Bayern Munich|         483980000|\n",
      "|  2013|     Dortmund|         285150000|\n",
      "|  2014|Bayern Munich|         564180000|\n",
      "|  2014|     Dortmund|         329800000|\n",
      "|  2015|Bayern Munich|         608500000|\n",
      "|  2015|     Dortmund|         311600000|\n",
      "|  2016|Bayern Munich|         595400000|\n",
      "|  2016|     Dortmund|         321550000|\n",
      "|  2017|Bayern Munich|         597950000|\n",
      "|  2017|     Dortmund|         416730000|\n",
      "+------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "w=Window().partitionBy(\"Season\")\n",
    "\n",
    "teams.withColumn(\n",
    "        \"rank\", F.row_number().over(w.orderBy(F.col(\"OverallMarketValue\").desc()))\n",
    ").filter(\n",
    "        (F.col(\"rank\")==1) | (F.col(\"rank\")==2)\n",
    ").drop(\"rank\").select('Season','TeamName','OverallMarketValue').show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, Bayern Munich is the team with more economic power of the Bundesliga teams, as every season it is the team with more market value of the league. The second most valuable team in the last years is Borussia Dortmund, while in the 2010s the second most valuable team used to be Werder Bremen. It's also remarkable the fact that every year the value of the team hasn't stopped of increase. This is because of the football market's inflation, that has grow a lot in the past 20 years. \n",
    "\n",
    "Now let's check the maximum values of the different teams across the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+--------------+\n",
      "|     TeamName|Season|MaxMarketValue|\n",
      "+-------------+------+--------------+\n",
      "|Bayern Munich|  2015|     608500000|\n",
      "|Bayern Munich|  2017|     597950000|\n",
      "|Bayern Munich|  2016|     595400000|\n",
      "|Bayern Munich|  2014|     564180000|\n",
      "|Bayern Munich|  2013|     483980000|\n",
      "|     Dortmund|  2017|     416730000|\n",
      "|Bayern Munich|  2012|     407300000|\n",
      "|Bayern Munich|  2011|     335600000|\n",
      "|     Dortmund|  2014|     329800000|\n",
      "|     Dortmund|  2016|     321550000|\n",
      "|     Dortmund|  2015|     311600000|\n",
      "|     Dortmund|  2013|     285150000|\n",
      "|Bayern Munich|  2010|     284500000|\n",
      "|Bayern Munich|  2009|     283250000|\n",
      "|    Wolfsburg|  2015|     265430000|\n",
      "|   Leverkusen|  2016|     244580000|\n",
      "|Bayern Munich|  2008|     238900000|\n",
      "|   Schalke 04|  2016|     238750000|\n",
      "|     Dortmund|  2012|     227680000|\n",
      "|    Wolfsburg|  2016|     225350000|\n",
      "+-------------+------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teams.groupBy('TeamName','Season').agg(\n",
    "    F.max('OverallMarketValue').alias('MaxMarketValue')\n",
    ").orderBy(F.col('MaxMarketValue').desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first team that appears in the list different from the Bayern Munich is Borussia dortmund. Both of this teams are the ones that appears most in the top list of market value. In the final spots of the list we have also two teams: Wolfsburg and Bayern Leverkusen. \n",
    "\n",
    "Now let's check the top 10 stadiums with most capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+\n",
      "|          TeamName|StadiumCapacity|\n",
      "+------------------+---------------+\n",
      "|          Dortmund|          81359|\n",
      "|     Bayern Munich|          75000|\n",
      "|            Hertha|          74475|\n",
      "|        Schalke 04|          62271|\n",
      "|         Stuttgart|          60449|\n",
      "|           Hamburg|          57376|\n",
      "|Fortuna Dusseldorf|          54600|\n",
      "|        M'gladbach|          54014|\n",
      "|     Ein Frankfurt|          51500|\n",
      "|          Nurnberg|          50000|\n",
      "+------------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "w=Window().partitionBy(\"TeamName\")\n",
    "\n",
    "teams.withColumn(\n",
    "        \"rank\", F.row_number().over(w.orderBy(F.col(\"StadiumCapacity\").desc()))\n",
    ").filter(\n",
    "        (F.col(\"rank\")==1)\n",
    ").drop(\"rank\").select('TeamName','StadiumCapacity').orderBy(\n",
    "        F.col('StadiumCapacity').desc()\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see Borussia Dortmund is the team with more capacity, followed by the Bayern Munich and by Hertha Berlin. Now we are going to see which teams are the youngest and the oldest ones in the teams we have. Starting with the older ones, this is the oldest teams that we have in our data across the years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+----------+\n",
      "|      TeamName|Season|AvgAgeHome|\n",
      "+--------------+------+----------+\n",
      "|         Ahlen|  2005|        28|\n",
      "|     Offenbach|  2006|        27|\n",
      "|      Hannover|  2007|        27|\n",
      "| Bayern Munich|  2005|        27|\n",
      "|      Augsburg|  2006|        27|\n",
      "|        Aachen|  2005|        27|\n",
      "|      Duisburg|  2005|        27|\n",
      "|     Wolfsburg|  2005|        27|\n",
      "|Erzgebirge Aue|  2006|        27|\n",
      "| Frankfurt FSV|  2008|        27|\n",
      "+--------------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teams.groupBy('TeamName','Season').agg(\n",
    "    F.max('AvgAgeHome').alias('AvgAgeHome')\n",
    ").orderBy(F.col('AvgAgeHome').desc()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the youngest teams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+----------+\n",
      "|      TeamName|Season|AvgAgeHome|\n",
      "+--------------+------+----------+\n",
      "|    RB Leipzig|  2015|        22|\n",
      "|    Hoffenheim|  2009|        22|\n",
      "|   Munich 1860|  2010|        22|\n",
      "|        Bochum|  2016|        22|\n",
      "|    Leverkusen|  2007|        23|\n",
      "|Kaiserslautern|  2011|        23|\n",
      "|    RB Leipzig|  2016|        23|\n",
      "|      Dortmund|  2006|        23|\n",
      "| Werder Bremen|  2014|        23|\n",
      "|       FC Koln|  2012|        23|\n",
      "+--------------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teams.groupBy('TeamName','Season').agg(\n",
    "    F.min('AvgAgeHome').alias('AvgAgeHome')\n",
    ").orderBy(F.col('AvgAgeHome')).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's remarkable that we found the older teams in our data in the earlier years of study, while we have the youngest teams in the last years of our study. This is probably because in the last years footballers have become professionals earlier, decreasing the teams' mean age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load of the matches df**\n",
    "\n",
    "Now we are going to load and take a look at the matches df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24625"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = spark.read.option(\"header\",True).option(\"inferSchema\" , \"true\").csv(\"./data/Matches.csv\")\n",
    "matches.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to ensure that in our matches df we don't have any foreign club. This could be a match of the another league or a match from a international clubs competition of a german club facing a foreign club, so we are going to impose that both teams are german."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15239"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = matches.join(\n",
    "    unique_german_teams,\n",
    "    on = [(unique_german_teams.TeamName == matches.HomeTeam)],\n",
    "    how='inner').drop(\n",
    "'Unique_Team_ID','TeamName').dropDuplicates().join(\n",
    "    unique_german_teams,\n",
    "    on = [(unique_german_teams.TeamName == matches.AwayTeam)],\n",
    "    how='inner').drop(\n",
    "    'Unique_Team_ID','TeamName').dropDuplicates()\n",
    "\n",
    "matches.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just have german teams playing with each other. We can see that maybe some variables are not very well named. We are going to change the names of the columns 'FTHG' and 'FTAG', which basically are the goals scored by the home team and by the away team, respectively.  Also, the final result, which is a categorical variable named as FTR, is not very explanatory, so we are going to rename it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-------------------+------------------+------------+---------+---------+------+\n",
      "|Match_ID|Div|Season|               Date|          HomeTeam|    AwayTeam|HomeGoals|AwayGoals|Result|\n",
      "+--------+---+------+-------------------+------------------+------------+---------+---------+------+\n",
      "|       7| D2|  2009|2009-08-14 00:00:00|         Paderborn|   Karlsruhe|        2|        0|     H|\n",
      "|      23| D1|  2009|2010-05-08 00:00:00|        M'gladbach|  Leverkusen|        1|        1|     D|\n",
      "|     366| D2|  2009|2010-01-22 00:00:00|Fortuna Dusseldorf|Union Berlin|        1|        0|     H|\n",
      "|     413| D2|  2009|2010-03-12 00:00:00|             Ahlen|     Koblenz|        0|        2|     A|\n",
      "|     861| D2|  2010|2011-01-22 00:00:00|           Cottbus|   Bielefeld|        2|        1|     H|\n",
      "+--------+---+------+-------------------+------------------+------------+---------+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matches = matches.withColumnRenamed(\n",
    "    'FTHG','HomeGoals'\n",
    ").withColumnRenamed(\n",
    "    'FTAG','AwayGoals'\n",
    ").withColumnRenamed(\n",
    "    'FTR','Result'\n",
    ")\n",
    "matches.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have a variable named Div, which indicates the division of the football teams that are playing the match. We want to analyse the Bundesliga, which corresponds to the first division (D1), so we are going to filter the df in order to just keep the matches of this division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7616"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = matches.filter(F.col('Div') == 'D1')\n",
    "matches.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to check what is the effect of being home team or away team in the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|Result|count(Result)|\n",
      "+------+-------------+\n",
      "|     D|         1872|\n",
      "|     A|         2009|\n",
      "|     H|         3735|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matches.groupBy('Result').agg(F.count('Result')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's much more frequent that the home team is the one who wins. Let's see who's the top 3 teams that win the most as visitor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|     AwayTeam|AwayVictories|\n",
      "+-------------+-------------+\n",
      "|Bayern Munich|          216|\n",
      "|   M'gladbach|          203|\n",
      "|      Hamburg|          203|\n",
      "|Werder Bremen|          192|\n",
      "|Ein Frankfurt|          186|\n",
      "+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matches.groupBy(\n",
    "    'Result','AwayTeam'\n",
    ").agg(\n",
    "    F.count('Result'),F.count('AwayTeam').alias('AwayVictories')\n",
    ").drop(\n",
    "    'Result','count(Result)'\n",
    ").orderBy(F.col('AwayVictories').desc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Questions answers](#toc0_)\n",
    "\n",
    "**Champions and relegateds of the Bundesliga year by year**\n",
    "\n",
    "Now let's check who where the Bundesliga winners and the three relegateds in the years between 2000 and 2015. Firstly, we are going to filter the matches of the seasons we are interested in, and then we are going to create three new columns with a 0 or a 1 depending on the result, indicating if the home team has won, has tied or has lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_00_15 = matches.filter((F.col('Season') >= 2000) & (F.col('Season') <= 2015))\n",
    "\n",
    "matches_00_15 = matches_00_15.withColumn(\n",
    "    'HomeTeamWin', F.when(F.col('Result') == 'H', 1).otherwise(0)\n",
    ").withColumn('AwayTeamWin', F.when(F.col('Result') == 'A', 1).otherwise(0)\n",
    ").withColumn(\n",
    "    'GameTie', F.when(F.col('Result') == 'D', 1).otherwise(0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create two dfs: one for the stats for each team when they play at home and the same for each team when they play as visitors. This way we then join both dfs and do some calculations in order to get the champions and relegateds for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+--------------+----------+-----------+--------------------+----------------------+---+------+\n",
      "|Season|         Team|TotalVictories|TotalDraws|TotalLosses|TotalTeamGoalsScored|TotalTeamGoalsConceded| +-|Points|\n",
      "+------+-------------+--------------+----------+-----------+--------------------+----------------------+---+------+\n",
      "|  2005|Bayern Munich|            22|         9|          3|                  67|                    32| 35|    75|\n",
      "|  2008|   M'gladbach|             8|         7|         19|                  39|                    62|-23|    31|\n",
      "+------+-------------+--------------+----------+-----------+--------------------+----------------------+---+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build the home team stats for each season\n",
    "hometeam = matches_00_15.groupBy(\n",
    "    'Season','HomeTeam'\n",
    ").agg(\n",
    "    F.sum(F.col('HomeTeamWin')).alias('TotalHomeWin'),\n",
    "    F.sum(F.col('GameTie')).alias('TotalHomeDraw'),\n",
    "    F.sum(F.col('AwayTeamWin')).alias('TotalHomeLoss'),\n",
    "    F.sum(F.col('HomeGoals')).alias('TotalHomeGoalsScored'),\n",
    "    F.sum(F.col('AwayGoals')).alias('TotalHomeGoalsConceded'),\n",
    ").withColumnRenamed('HomeTeam', 'Team')\n",
    "\n",
    "# build the away team stats for each season\n",
    "awayteam = matches_00_15.groupBy(\n",
    "    'Season','AwayTeam'\n",
    ").agg(\n",
    "    F.sum(F.col('HomeTeamWin')).alias('TotalAwayLoss'),\n",
    "    F.sum(F.col('GameTie')).alias('TotalAwayDraw'),\n",
    "    F.sum(F.col('AwayTeamWin')).alias('TotalAwayWin'),\n",
    "    F.sum(F.col('AwayGoals')).alias('TotalAwayGoalsScored'),\n",
    "    F.sum(F.col('HomeGoals')).alias('TotalAwayGoalsConceded'),\n",
    ").withColumnRenamed('AwayTeam', 'Team')\n",
    "\n",
    "# combine the previous dfs and get general season stats\n",
    "total_results_season = hometeam.join(awayteam, on=['Season','Team'],how='inner')\n",
    "total_results_season = total_results_season.withColumn(\n",
    "    'TotalVictories',F.col('TotalHomeWin') + F.col('TotalAwayWin')\n",
    ").withColumn(\n",
    "    'TotalDraws',F.col('TotalHomeDraw') + F.col('TotalAwayDraw')\n",
    ").withColumn(\n",
    "    'TotalLosses',F.col('TotalHomeLoss') + F.col('TotalAwayLoss')\n",
    ").withColumn(\n",
    "    'TotalTeamGoalsScored',F.col('TotalHomeGoalsScored') + F.col('TotalAwayGoalsScored')\n",
    ").withColumn(\n",
    "    'TotalTeamGoalsConceded',F.col('TotalHomeGoalsConceded') + F.col('TotalAwayGoalsConceded')\n",
    ").withColumn(\n",
    "    '+-',F.col('TotalTeamGoalsScored') - F.col('TotalTeamGoalsConceded')\n",
    ").withColumn(\n",
    "    'Points', (F.col('TotalHomeWin') + F.col('TotalAwayWin'))*3 + (F.col('TotalHomeDraw') + F.col('TotalAwayDraw'))*1\n",
    ").drop('TotalHomeWin', 'TotalHomeDraw', 'TotalHomeLoss', 'TotalHomeGoalsScored','TotalHomeGoalsConceded', 'TotalAwayLoss', 'TotalAwayDraw', 'TotalAwayWin','TotalAwayGoalsScored','TotalAwayGoalsConceded')\n",
    "\n",
    "total_results_season.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the df built and we in order to get the champions and relegateds for each year we only have to filter that information from it. Firstly we want to get the champions for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+------+\n",
      "|Season|         Team|Points|\n",
      "+------+-------------+------+\n",
      "|  2000|Bayern Munich|    63|\n",
      "|  2001|     Dortmund|    70|\n",
      "|  2002|Bayern Munich|    75|\n",
      "|  2003|Werder Bremen|    74|\n",
      "|  2004|Bayern Munich|    77|\n",
      "|  2005|Bayern Munich|    75|\n",
      "|  2006|    Stuttgart|    70|\n",
      "|  2007|Bayern Munich|    76|\n",
      "|  2008|    Wolfsburg|    69|\n",
      "|  2009|Bayern Munich|    70|\n",
      "|  2010|     Dortmund|    75|\n",
      "|  2011|     Dortmund|    81|\n",
      "|  2012|Bayern Munich|    91|\n",
      "|  2013|Bayern Munich|    90|\n",
      "|  2014|Bayern Munich|    79|\n",
      "|  2015|Bayern Munich|    88|\n",
      "+------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w=Window().partitionBy('Season')\n",
    "\n",
    "total_results_season.withColumn(\n",
    "        \"rank\", F.row_number().over(w.orderBy(F.col(\"Points\").desc()))\n",
    ").filter(\n",
    "        (F.col(\"rank\")==1)\n",
    ").drop(\"rank\").select('Season','Team','Points').orderBy(\n",
    "        F.col('Season')\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The teams that mostly won the leaguer in the last years are the ones that before we have seen have most money: Bayern Munich and Dortmund. We are surprised by the presence of Stuttgart in 2006. Let's check now the three relegateds of each year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+------+\n",
      "|Season|          Team|Points|\n",
      "+------+--------------+------+\n",
      "|  2000|  Unterhaching|    35|\n",
      "|  2000| Ein Frankfurt|    35|\n",
      "|  2000|        Bochum|    27|\n",
      "|  2001|      St Pauli|    22|\n",
      "|  2001|      Freiburg|    30|\n",
      "|  2001|       FC Koln|    29|\n",
      "|  2002|      Nurnberg|    30|\n",
      "|  2002|     Bielefeld|    36|\n",
      "|  2002|       Cottbus|    30|\n",
      "|  2003|   Munich 1860|    32|\n",
      "|  2003| Ein Frankfurt|    32|\n",
      "|  2003|       FC Koln|    23|\n",
      "|  2004| Hansa Rostock|    30|\n",
      "|  2004|        Bochum|    35|\n",
      "|  2004|      Freiburg|    18|\n",
      "|  2005|       FC Koln|    30|\n",
      "|  2005|Kaiserslautern|    33|\n",
      "|  2005|      Duisburg|    27|\n",
      "|  2006|    M'gladbach|    26|\n",
      "|  2006|         Mainz|    34|\n",
      "+------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w=Window().partitionBy('Season')\n",
    "\n",
    "total_results_season.withColumn(\n",
    "        \"rank\", F.row_number().over(w.orderBy(F.col(\"Points\")))\n",
    ").filter(\n",
    "        (F.col(\"rank\")==1) | (F.col(\"rank\")==2) | (F.col(\"rank\")==3)\n",
    ").drop(\"rank\").select('Season','Team','Points').orderBy(\n",
    "        F.col('Season')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Season with more goals**\n",
    "\n",
    "Now let's see in which of the seasons of study had more goals scored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+\n",
      "|Season|TotalSeasonGoals|\n",
      "+------+----------------+\n",
      "|  2013|             967|\n",
      "|  2003|             909|\n",
      "|  2012|             898|\n",
      "|  2000|             897|\n",
      "|  2010|             894|\n",
      "|  2008|             894|\n",
      "|  2001|             893|\n",
      "|  2004|             890|\n",
      "|  2011|             875|\n",
      "|  2009|             866|\n",
      "|  2015|             866|\n",
      "|  2005|             861|\n",
      "|  2007|             860|\n",
      "|  2014|             843|\n",
      "|  2006|             837|\n",
      "|  2002|             821|\n",
      "+------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "more_goals_season = matches_00_15.withColumn(\n",
    "    'TotalGameGoals', F.col('HomeGoals') + F.col('AwayGoals')\n",
    ").drop(\n",
    "    'Match_ID','Div','Date','HomeTeam','AwayTeam','HomeGoals','AwayGoals'\n",
    ").groupBy(\n",
    "    'Season'\n",
    ").agg(\n",
    "    F.sum('TotalGameGoals').alias('TotalSeasonGoals')\n",
    ").orderBy(F.col('TotalSeasonGoals').desc())\n",
    "\n",
    "more_goals_season.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Random Forest model to predict result](#toc0_)\n",
    "We are going to modify the df in order to try to predict the result of the match based in some features. We've chosen the use of a RF because with it we can check the feature importances, and because it's a well known and a very used model (remember that, as we said before, we want to do a simple model building a pipeline using Pyspark). This will be a simple model and it'll be difficult to obtain nice results with it because the result of a football match depends on a lot of factors that we don't have stored (injured players of each team and the dependency on that players of the team, weather of that day, assistance of that match...). Nevertheless, even if we had the majority of them, it would be very difficult to predict the result because it can depend on other important factors that can't be monitorised, such as the emotional situation of each player. It's remarkable to say that, as we have seen previously, we have approximattely 2000 draws, 2000 away victories and 3800 home victories, so we are facing a more or less balanced classes problem (we don't have a class that is much more numerous than the others).\n",
    "\n",
    "With the data we have, we want to modify the matches df, adding the market value of each team, the home team stadium capacity and the avg age of each team to it (this can be important because in football the experience is a very important factor in order to have a good pressure management). We just want to know the result, not the score, so we drop the info about the goals (also, if we had it in the features to predict, the model would have no sense because it wouldn't failed); we don't care about the date of the match, so we delete it. We will also delete (when all the pertinent joins that need these variables are done) the Season and the TeamName columns, because they don't give any information and we don't want them to be variables with which to predict.\n",
    "\n",
    "### <a id='toc1_3_1_'></a>[Prediction of matches with wins, losses and draws](#toc0_)\n",
    "\n",
    "We'll start our analysis trying to predict the result of the match as it is in reality; it can be a win, a draw or a loss of the home team. Having the class \"Draw\"  adds dificulty to the problem, because it's more likely that a more powerful team ties with a smaller team that losses to it. Nevertheless, we are going to try to predict the result with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+-------------------+-------------------+--------------+-------------------+\n",
      "|Result|AvgAgeHomeTeam|MarketValueHomeTeam|HomeStadiumCapacity|AvgAgeAwayTeam|MarketValueAwayTeam|\n",
      "+------+--------------+-------------------+-------------------+--------------+-------------------+\n",
      "|     D|            25|           45800000|              54014|            24|          109050000|\n",
      "|     H|            25|          122000000|              30000|            23|           43180000|\n",
      "|     D|            23|           43180000|              50000|            23|          125350000|\n",
      "|     A|            23|           43180000|              50000|            23|           93600000|\n",
      "|     D|            23|           45450000|              24000|            23|          115900000|\n",
      "+------+--------------+-------------------+-------------------+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "We divide the unions in some steps to explain the sequence step by step. Firstly we filter the matches df we want and drop the variables we don't want. \n",
    "Then we do an inner join with teams df by TeamName and Season to get the information of each home team for every season (mean of age, market value and \n",
    "stadium capacity), renaming the variables propperly and dropping some duplicate variables result of the join.\n",
    "'''\n",
    "study_df = matches.filter(\n",
    "    (F.col('Season') >= 2000) & (F.col('Season') <= 2015)\n",
    ").drop(\n",
    "    'Match_ID','Date','AwayGoals','HomeGoals','Div'\n",
    ").join(\n",
    "    teams,\n",
    "    on = [(teams.TeamName == matches.HomeTeam) & (teams.Season == matches.Season)],\n",
    "    how='inner'\n",
    ").withColumnRenamed(\n",
    "    'StadiumCapacity','HomeStadiumCapacity'\n",
    ").withColumnRenamed(\n",
    "    'OverallMarketValue','MarketValueHomeTeam'\n",
    ").withColumnRenamed(\n",
    "    'AvgAgeHome','AvgAgeHomeTeam'\n",
    ").drop(\n",
    "    teams.Season\n",
    ").drop(\n",
    "    teams.TeamName\n",
    ")\n",
    "\n",
    "'''\n",
    "After that we do an inner join of the previous df with teams df by TeamName and Season to get the information of each away team for every season, \n",
    "(avg age and market value), renaming the variables propperly and dropping some duplicate variables result of the join.\n",
    "'''\n",
    "\n",
    "study_df = study_df.join(\n",
    "    teams,\n",
    "    on = [(teams.TeamName == matches.AwayTeam) & (teams.Season == matches.Season)],\n",
    "    how='inner'\n",
    ").withColumnRenamed(\n",
    "    'OverallMarketValue','MarketValueAwayTeam'\n",
    ").withColumnRenamed(\n",
    "    'AvgAgeHome','AvgAgeAwayTeam'\n",
    ").drop(\n",
    "    teams.Season\n",
    ").drop(\n",
    "    teams.StadiumCapacity\n",
    ").drop(\n",
    "    teams.TeamName\n",
    ").drop(\n",
    "    matches.Season\n",
    ").drop(\n",
    "    'TeamName','StadiumCapacity','Season'\n",
    ")\n",
    "\n",
    "''' \n",
    "Finally we drop the HomeTeam and AwayTeam name.\n",
    "'''\n",
    "\n",
    "study_df = study_df.drop(\n",
    "    'HomeTeam','AwayTeam'\n",
    ")\n",
    "\n",
    "study_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to use the *pyspark.ml.VectorAssembler* to load all the features we want for our model into a single feature vector in order to train our model. This columns will be all the independent columns (all the columns except from Result). We also have to encode the Result column, and we do so using the StringIndexer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "\n",
    "# define an instance of assembler\n",
    "assembler = VectorAssembler(inputCols= ['AvgAgeHomeTeam', 'MarketValueHomeTeam', 'HomeStadiumCapacity', 'AvgAgeAwayTeam', 'MarketValueAwayTeam'],\n",
    "                            outputCol='features')\n",
    "\n",
    "# StringIndexer encodes a string column of labels to a column of label indices. The indices are in [0, numLabels), ordered by label frequencies, so \n",
    "# #the most frequent label gets index 0. In our case, the label column (Result) will be encoded to label indices, from 0 to 3; the most frequent label\n",
    "#  (H) will be indexed as 0.\n",
    "label_stringIdx = StringIndexer(inputCol = 'Result', outputCol = 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a pipeline with these two stages and create a df with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+-------------------+-------------------+--------------+-------------------+--------------------+-----+\n",
      "|Result|AvgAgeHomeTeam|MarketValueHomeTeam|HomeStadiumCapacity|AvgAgeAwayTeam|MarketValueAwayTeam|            features|label|\n",
      "+------+--------------+-------------------+-------------------+--------------+-------------------+--------------------+-----+\n",
      "|     D|            25|           45800000|              54014|            24|          109050000|[25.0,4.58E7,5401...|  2.0|\n",
      "|     H|            25|          122000000|              30000|            23|           43180000|[25.0,1.22E8,3000...|  0.0|\n",
      "+------+--------------+-------------------+-------------------+--------------+-------------------+--------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[25.0,4.58E7,5401...|  2.0|\n",
      "|[25.0,1.22E8,3000...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages = [assembler, label_stringIdx])\n",
    "\n",
    "pipelineModel = pipeline.fit(study_df)\n",
    "df = pipelineModel.transform(study_df)\n",
    "df.show(2)\n",
    "\n",
    "#we just want the columns features and label, which are the ones we'll use for the model\n",
    "df = df.select('features','label')\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could have been done without using the ML Pipeline, but, as we can see below it's much more longer and messy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+------+\n",
      "|features                           |Result|\n",
      "+-----------------------------------+------+\n",
      "|[25.0,4.58E7,54014.0,24.0,1.0905E8]|D     |\n",
      "+-----------------------------------+------+\n",
      "only showing top 1 row\n",
      "\n",
      "+------+--------------+-------------------+-------------------+--------------+-------------------+--------------------+-----+\n",
      "|Result|AvgAgeHomeTeam|MarketValueHomeTeam|HomeStadiumCapacity|AvgAgeAwayTeam|MarketValueAwayTeam|            features|label|\n",
      "+------+--------------+-------------------+-------------------+--------------+-------------------+--------------------+-----+\n",
      "|     D|            25|           45800000|              54014|            24|          109050000|[25.0,4.58E7,5401...|  2.0|\n",
      "+------+--------------+-------------------+-------------------+--------------+-------------------+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[25.0,4.58E7,5401...|  2.0|\n",
      "+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "\n",
    "# define an instance of assembler\n",
    "assembler = VectorAssembler(inputCols= ['AvgAgeHomeTeam', 'MarketValueHomeTeam', 'HomeStadiumCapacity', 'AvgAgeAwayTeam', 'MarketValueAwayTeam'],\n",
    "                            outputCol='features')\n",
    "\n",
    "# transform our df\n",
    "study_df_assembled = assembler.transform(study_df)\n",
    "\n",
    "# we now have all the features in just one variable\n",
    "study_df_assembled.select('features','Result').show(1,truncate=False)\n",
    "\n",
    "# Now we use the StringIndexer with the column  result for that previously transformed df\n",
    "label_stringIdx = StringIndexer(inputCol = 'Result', outputCol = 'label')\n",
    "\n",
    "model_df = label_stringIdx.fit(study_df_assembled).transform(study_df_assembled)\n",
    "model_df.show(1)\n",
    "model_df = model_df.select('features','label')\n",
    "model_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we divide into training and test df using Randomsplit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df count: 3366, \n",
      " Training df count: 2377, \n",
      " Test df count: 989\n"
     ]
    }
   ],
   "source": [
    "training_df, test_df = df.randomSplit([0.7,0.3])\n",
    "print(f'Original df count: {df.count()}, \\n Training df count: {training_df.count()}, \\n Test df count: {test_df.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to import and to use the RandomForest model. we firstly fit the model using the training df and then we predict with the test df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[22.0,9.063E7,301...|  2.0|[25.7653589578414...|[0.51530717915682...|       0.0|\n",
      "|[22.0,9.063E7,301...|  0.0|[25.6622916233822...|[0.51324583246764...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    labelCol='label', numTrees= 50\n",
    ").fit(\n",
    "    training_df\n",
    ")\n",
    "\n",
    "labels_pred = rf_classifier.transform(test_df)\n",
    "labels_pred.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some classification metrics of our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47219413549039435\n",
      "weightedPrecision: 0.39083118581167287\n",
      "weightedRecall: 0.47219413549039435\n",
      "f1: 0.3988346356865378\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "#accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName='accuracy')\n",
    "print(f'Accuracy: {evaluator.evaluate(labels_pred)}')\n",
    "\n",
    "#precision\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName='weightedPrecision')\n",
    "print(f'weightedPrecision: {evaluator.evaluate(labels_pred)}')\n",
    "\n",
    "#recall\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName='weightedRecall')\n",
    "print(f'weightedRecall: {evaluator.evaluate(labels_pred)}')\n",
    "\n",
    "#f1\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName='f1')\n",
    "print(f'f1: {evaluator.evaluate(labels_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we have obtained a very poor results: an accuracy of less than 50 % dissapointing, as well as the results of the precision and the recall. The f1 score, which is the harmonic mean of these last two metrics and has a value of 0.38, is another sign that the results are very bad. \n",
    "\n",
    "Lastly we are going to analyse the feature importances of our model. Feature importance refers to techniques that assign a score to input features based on how useful they are at predicting a target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AvgAgeHomeTeam', 'MarketValueHomeTeam', 'HomeStadiumCapacity', 'AvgAgeAwayTeam', 'MarketValueAwayTeam']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SparseVector(5, {0: 0.0458, 1: 0.3699, 2: 0.1623, 3: 0.0599, 4: 0.3621})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(study_df.drop('Result').columns)\n",
    "rf_classifier.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the most important variables, with lots of difference, are the MarketValue of both teams. The third most important variable is the capacity of the Home stadium and lastly the most irrelevant features are the ones related with the age of the teams. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_2_'></a>[Prediction of matches with no Draws](#toc0_)\n",
    "\n",
    "As we have said before, this class adds difficulty to the problem. As we have obtained very bad results, let's check whether removing this class helps the model to improve its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2516"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_df = study_df.filter(F.col('Result')!= 'D')\n",
    "study_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|Result|count(Result)|\n",
      "+------+-------------+\n",
      "|     A|         1001|\n",
      "|     H|         1515|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "study_df.groupBy('Result').agg(F.count('Result')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have a more or less balanced problem. As before, we are going to apply the Pipeline previously created to the new df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+-------------------+-------------------+--------------+-------------------+--------------------+-----+\n",
      "|Result|AvgAgeHomeTeam|MarketValueHomeTeam|HomeStadiumCapacity|AvgAgeAwayTeam|MarketValueAwayTeam|            features|label|\n",
      "+------+--------------+-------------------+-------------------+--------------+-------------------+--------------------+-----+\n",
      "|     H|            25|          122000000|              30000|            23|           43180000|[25.0,1.22E8,3000...|  0.0|\n",
      "|     A|            23|           43180000|              50000|            23|           93600000|[23.0,4.318E7,500...|  1.0|\n",
      "+------+--------------+-------------------+-------------------+--------------+-------------------+--------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[25.0,1.22E8,3000...|  0.0|\n",
      "|[23.0,4.318E7,500...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages = [assembler, label_stringIdx])\n",
    "\n",
    "pipelineModel = pipeline.fit(study_df)\n",
    "df = pipelineModel.transform(study_df)\n",
    "df.show(2)\n",
    "\n",
    "#we just want the columns features and label, which are the ones we'll use for the model\n",
    "df = df.select('features','label')\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we divide into training and test df using Randomsplit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df count: 2516, \n",
      " Training df count: 1758, \n",
      " Test df count: 758\n"
     ]
    }
   ],
   "source": [
    "training_df, test_df = df.randomSplit([0.7,0.3])\n",
    "print(f'Original df count: {df.count()}, \\n Training df count: {training_df.count()}, \\n Test df count: {test_df.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to import and to use the RandomForest model. we firstly fit the model using the training df and then we predict with the test df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[22.0,9.063E7,301...|  0.0|[31.3620352742704...|[0.62724070548540...|       0.0|\n",
      "|[22.0,9.063E7,301...|  1.0|[30.0291010894482...|[0.60058202178896...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    labelCol='label', numTrees= 50\n",
    ").fit(\n",
    "    training_df\n",
    ")\n",
    "\n",
    "labels_pred = rf_classifier.transform(test_df)\n",
    "labels_pred.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some classification metrics of our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6503957783641161\n",
      "weightedPrecision: 0.6450378278797431\n",
      "weightedRecall: 0.6503957783641161\n",
      "f1: 0.6168232579120898\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "#accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName='accuracy')\n",
    "print(f'Accuracy: {evaluator.evaluate(labels_pred)}')\n",
    "\n",
    "#precision\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName='weightedPrecision')\n",
    "print(f'weightedPrecision: {evaluator.evaluate(labels_pred)}')\n",
    "\n",
    "#recall\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName='weightedRecall')\n",
    "print(f'weightedRecall: {evaluator.evaluate(labels_pred)}')\n",
    "\n",
    "#f1\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName='f1')\n",
    "print(f'f1: {evaluator.evaluate(labels_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the results we have obtained are better than the previous one with the label \"Draw\" (as we expected), but they aren't very good, with an accuracy value of 0.66 and a f1 score of 0.64."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we are going to analyse the feature importances of our model. Feature importance refers to techniques that assign a score to input features based on how useful they are at predicting a target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AvgAgeHomeTeam', 'MarketValueHomeTeam', 'HomeStadiumCapacity', 'AvgAgeAwayTeam', 'MarketValueAwayTeam']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SparseVector(5, {0: 0.0404, 1: 0.3505, 2: 0.1792, 3: 0.0461, 4: 0.3837})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(study_df.drop('Result').columns)\n",
    "rf_classifier.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before the most important variables are the MarketValue of both teams, the third most important variable is the capacity of the Home stadium and lastly the most irrelevant features are the ones related with the age of the teams. \n",
    "\n",
    "**Grid Search trying to improve the results**\n",
    "\n",
    "Finally we are going to try doing a GridSearch in order to obtain the best hyperparameters of the model, with the hope to improve the results obtained. We have tried to improve the accuracy, because we have a balanced classes problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 17:10:33 WARN DAGScheduler: Broadcasting large task binary with size 1122.5 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 17:13:41 WARN DAGScheduler: Broadcasting large task binary with size 1162.4 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 17:13:48 WARN DAGScheduler: Broadcasting large task binary with size 1024.3 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 17:16:38 WARN DAGScheduler: Broadcasting large task binary with size 1114.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 17:19:49 WARN DAGScheduler: Broadcasting large task binary with size 1073.7 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "paramGrid = ParamGridBuilder().addGrid(\n",
    "    rf.numTrees, [20, 30,50,80]\n",
    ").addGrid(\n",
    "    rf.maxDepth, [3, 5, 7]\n",
    ").build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator= MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName='accuracy'),\n",
    "                          numFolds=4) \n",
    "\n",
    "cvModel = crossval.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Param(parent='RandomForestClassifier_53e00e6b96f8', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='RandomForestClassifier_53e00e6b96f8', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 3}\n",
      "Accuracy: 0.6543535620052771\n",
      "weightedPrecision: 0.6521333069767574\n",
      "weightedRecall: 0.6543535620052771\n",
      "f1: 0.6185221027428494\n"
     ]
    }
   ],
   "source": [
    "# print the best hyperparameters values\n",
    "import numpy as np\n",
    "print(cvModel.getEstimatorParamMaps()[ np.argmax(cvModel.avgMetrics) ])\n",
    "\n",
    "# now we predict the labels using the best model\n",
    "bestModel = cvModel.bestModel\n",
    "labels_pred = bestModel.transform(test_df)\n",
    "\n",
    "#accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName='accuracy')\n",
    "print(f'Accuracy: {evaluator.evaluate(labels_pred)}')\n",
    "\n",
    "#precision\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName='weightedPrecision')\n",
    "print(f'weightedPrecision: {evaluator.evaluate(labels_pred)}')\n",
    "\n",
    "#recall\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName='weightedRecall')\n",
    "print(f'weightedRecall: {evaluator.evaluate(labels_pred)}')\n",
    "\n",
    "#f1\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName='f1')\n",
    "print(f'f1: {evaluator.evaluate(labels_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that using a Grid Search trying to optimize the hyperparameters we haven't obtained a much better results; in fact, we have got almost the same result as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Conclussions](#toc0_)\n",
    "\n",
    "We have obtained a very bad results with our model, but, as we commented before, it was expected: we are trying to predict a very complex thing as it is the result of a match with just the market value of the teams, the stadium where the match is played capacity and the age of the teams. Football matches are much more complex than that and a lot of factors influence on it: injured players of each team and the dependency on that players of the team, weather of that day, assistance of that match, nearby of international competition games that might do the coaches let the best players rest or even, as we have commented before, the emotional situation of each player. \n",
    "\n",
    "With this all, we don't have enough data to obtain a good result for our model, and, even if we had it, this wouldn't be enough to predict with lot of confidence the result. This is football is a sport and, as a result, even if we had all the data we have stated before, we can't take in account another crucial factor: the luck.\n",
    "\n",
    "Leaving aside all these, we have accomplished the goal of this job, which was work with pyspark, transforming dfs and building ML pipelines with this tool."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
